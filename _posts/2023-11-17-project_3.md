# Project 3 - Supervised Learning and Categorical Prediction *(R Studio)*

[project 3 landing page](https://bphigg.github.io/558Project3/)  
[project 3 repo](https://github.com/bphigg/558Project3)

For this project we want to build and compare model results to predict if an individual would have diabetes or not and how these predictions change with respect to the education level of the patient. Do do this, we will create a Rmd file that will produce EDA and training models and evaluate the models' performance on test data. We will then **automate** this file to run for each education level and select the best performance model. The diabetes data we will utilize is the [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/) available through Kaggle.

I thought the data set for this project was somewhat challenging. There were over 20 variables within the dataset and most related to physiological and medical indicators. I believe this led to a lot of correlation between the variables - bad health indicators in one variable being related to bad health indicators in other variables. We know that highly correlated predictors are generally not good for modeling and while building and testing models I found that the Accuracy rating on the test set was not much better than the "dumb" method of just predicting that everyone does not have diabetes. I concluded that there was just not enough non-correlated data available for the models to produce meaningful results.

Computer processing power was also an issue towards the end that, unfortunately, we were not able to solve. Two of our models, Random Forest and Support Vector Machine, took an lot of processing time. We tried parallel computing these models using the `doParallel` package with the `caret::train()` function but it did not appear to increase processing time. Additionally, I think the `doParallel` also resulted in package conflict issues since other models began to throw errors. Had we known about the processing time earlier, it would have been nice to be able to work and experiment more with implementing parallel computing in the `caret` environment. As it is, the dataset for the last level `CollegeGrad`, was too large for the `svm` model to process - we kept getting errors regarding vector length and memory.

It was good getting accustomed to **github**. Once it was understood how to construct pages through the repo, it became pretty simple to work with. Lastly, it was helpful to think about the automation process while creating and collaborating with a partner. A number of times we had to balance the implementation of an edit or change with the effects it would have on the automation process - how would one change ripple effect through the rest of the processes.
